#%%
import torch
import os
import pandas as pd
import torch.nn as nn
import matplotlib.pyplot as plt
from typing import Tuple
import copy
from torch.utils.data import DataLoader, TensorDataset

from lib.data_utils import preprocess
#from lib.config import DEVICE
from lib.model import AgePredictor
#%%

def evaluate_centralmodel(test_path: str, best_model: nn.Module, scaler, DEVICE) -> float:
    """
    Evaluates a centrally trained model on a given test dataset.

    Args:
        test_path (str): Path to the test dataset.
        best_model (nn.Module): Trained PyTorch model to evaluate.
        scaler: Scaler object used for feature normalization.

    Returns:
        float: Average mean absolute error (MAE) loss on the test set.
    """
    X_test, y_test, silo_name = preprocess(test_path)

    best_model.eval()
    best_model.to(DEVICE)
    X_test = scaler.transform(X_test)

    test_loader = DataLoader(
        TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)),
        batch_size=32
    )

    total_loss = 0.0
    criterion = nn.L1Loss()

    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            predictions = best_model(X_batch).view(-1, 1)
            total_loss += criterion(predictions, y_batch.view(-1, 1)).item()

    avg_loss = total_loss / len(test_loader)
    return avg_loss


def evaluate_model(test_path: str, model: nn.Module, scaler, DEVICE) -> float:
    """
    Evaluates a model (e.g., from a silo) on its respective test set.

    Args:
        test_path (str): Path to the test dataset.
        model (nn.Module): Trained PyTorch model.
        scaler: Scaler used for feature normalization.

    Returns:
        float: Average mean absolute error (MAE) loss on the test set.
    """
    X_test_raw, y_test, silo_name = preprocess(test_path)

    model.eval()
    X_test = scaler.transform(X_test_raw)

    test_loader = DataLoader(
        TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)),
        batch_size=32,
        shuffle=False
    )

    criterion = nn.L1Loss()
    total_loss = 0.0

    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            predictions = model(X_batch)
            total_loss += criterion(predictions.view(-1, 1), y_batch.view(-1, 1)).item()

    return total_loss / len(test_loader)


def predict_age(model: nn.Module, test_path: str, result_path: str, scaler, name) -> None:
    """
    Predicts age using a trained model and saves the predictions and a plot.

    Args:
        model (nn.Module): Trained PyTorch model.
        test_path (str): Path to the test dataset.
        result_path (str): Directory where prediction results and plots will be saved.
        scaler: Scaler used for feature normalization.

    Returns:
        None
    """
    X_test_raw, y_test, silo_name = preprocess(test_path)

    model.eval()
    X_test = scaler.transform(X_test_raw)

    test_loader = DataLoader(
        TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test)),
        batch_size=32,
        shuffle=False
    )

    predictions_list = []
    actual_age_list = []

    with torch.no_grad():
        for X_batch, Y_batch in test_loader:
            X_batch = X_batch.to('cuda')
            predictions = model(X_batch)
            predictions_list.extend(predictions.cpu().numpy().flatten())
            actual_age_list.extend(Y_batch.numpy().flatten())

    results_df = pd.DataFrame({
        'Actual_Age': actual_age_list,
        'Predicted_Age': predictions_list
    })

    result_age_path = os.path.join(result_path, f'Predictions_{silo_name}_{name}.csv')
    os.makedirs(os.path.dirname(result_age_path), exist_ok=True)
    results_df.to_csv(result_age_path, index=False)
    print(f"Saved predictions to {result_age_path}")

    # Plot predicted vs actual age
    plt.figure(figsize=(8, 6))
    plt.scatter(actual_age_list, predictions_list, alpha=0.5, label='Predictions')
    plt.plot(
        [min(actual_age_list), max(actual_age_list)],
        [min(actual_age_list), max(actual_age_list)],
        'r--',
        label='45Â° Line'
    )
    plt.xlabel('Actual Age')
    plt.ylabel('Predicted Age')
    plt.title(f'Predicted vs Actual Age ({silo_name})')
    plt.legend()
    plt.grid(True)

    plot_path = os.path.join(result_path, f'Predicted_vs_Actual_Age_{silo_name}_{name}.png')
    os.makedirs(os.path.dirname(plot_path), exist_ok=True)
    plt.savefig(plot_path)
    plt.close()

def compute_validation_loss(
    gmodel: nn.Module,
    val_loader: DataLoader,
    criterion: nn.Module,
    current_best_loss: float,
    current_best_model: nn.Module,
    epoch: int,
    best_epoch: int,
    device: torch.device
) -> Tuple[float, nn.Module]:
    """
    Calculate validation loss and return the best model (either current or previous best)
    
    Parameters
    ----------
    gmodel : nn.Module
        Current global model to evaluate
    val_loader : DataLoader
        Validation dataloader
    criterion : nn.Module
        Loss criterion
    current_best_loss : float
        Best validation loss from previous epochs
    current_best_model : nn.Module
        Best model from previous epochs
    device : torch.device
        Device for computation
    
    Returns
    -------
    Tuple[float, nn.Module]
        Updated best validation loss and corresponding model
    """
    gmodel.eval()
    total_loss = 0.0
    
    with torch.no_grad():
        for X_batch, y_batch in val_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            y_batch = y_batch.view(-1, 1)
            
            outputs = gmodel(X_batch).view(-1, 1)
            loss = criterion(outputs, y_batch)
            total_loss += loss.item()
    
    val_loss = total_loss / len(val_loader)
    
    # Compare with current best and return appropriate model
    if val_loss < current_best_loss:
        print(f"New best validation loss: {val_loss:.4f} (improved from {current_best_loss:.4f})")
        return val_loss, copy.deepcopy(gmodel),max(epoch,best_epoch)
    else:
        print(f"Validation loss: {val_loss:.4f} (no improvement from {current_best_loss:.4f})")
        return current_best_loss, current_best_model,best_epoch